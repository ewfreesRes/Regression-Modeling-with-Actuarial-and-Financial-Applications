---
title: Unusual observations
key: 3958fa9f4bc063310c17d368a7ad400d

---
## Unusual observations

```yaml
type: TitleSlide
key: 016e8a625f
```





`@lower_third`
name: Frees
title: Instructor




---
## Unusual observations

```yaml
type: FullSlide
key: 3cf4afb8b5
```

`@part1`
- Regression coefficients can be expressed as (matrix) weighted averages of outcomes
    - Averages, even weighted averages can be strongly influenced by unusual observations
- Observations may be unusual in the *y* direction or in the *X* space
- For unusual in the *y* direction, we use a residual $e = y - \hat{y}$
    - By subtracting the fitted value $\hat{y}$, we look to the *y* distance from the regression plane
    - In this way, we "control" for values of explanatory variables








---
## Standardized residuals

```yaml
type: FullSlide
key: b8e806195b
```

`@part1`
We standardize residuals so that we can focus on relationships of interest.

Three commonly used definitions of standardize residuals are:

$$
\text{(a) }\frac{e_i}{s}, \text{ (b) }\frac{e_i}{s\sqrt{1-h{ii}}}, \text{(c)}\frac{e_i}{s{(i)}\sqrt{1-h{ii}}}.
$$

- First choice is simple
- Second choice, from theory, $\text{Var}(e_i)=\sigma ^{2}(1-h{ii}).$ Here, $h{ii}$ is the *i*th *leverage* (defined later).
- Third choice is termed "studentized residuals".  (Idea: numerator is independent of the denominator.)





`@script`




---
## Outlier - an unusual standardized residual

```yaml
type: FullSlide
key: 193c40a4f8
```

`@part1`
- An *outlier* is an observation that is not well fit by the model; these are observations where the residual is unusually large.
- Unusual means what?  Many packages mark a point if the |standardized residual| > 2.
- Options for handling outliers
    - Ignore them in the analysis but be sure to discuss their effects.
    - Delete them from the data set (but be sure to discuss their effects).
    - Create a binary variable to indicate their presence. (This will increase your $R^2$!)





`@script`




---
## High leverage points

```yaml
type: FullSlide
key: 2dd10c2c4b
```

`@part1`
- A high leverage point is an observation that is "far away" in the $x$-space from others.
- Options for dealing with high leverage points are comparable to outliers, we can ignore their effects, delete them, or mark them with a binary indicator variable.
- One can get a feel for high leverage observations by looking a summary statistics (mins, maxs) for each explanatory variable.
- However, this is not sufficient - see the following graph .
    - The ellipsoid represents most of the data. 
    - The arrow marks a high leverage point that is **not unusual** for $x_1$ or for $x_2$.





`@script`




---
## High leverage point graph

```yaml
type: FullImageSlide
key: 1440b16ddf
```

`@part1`
![](https://assets.datacamp.com/production/repositories/2610/datasets/e1c25a0bc2ed021b66e7a333ef7cd02b41e35416/Ch4HighLeverage.png)








---
## Leverage

```yaml
type: FullSlide
key: 6b63c2bca3
```

`@part1`
- The *i*th fitted value as a linear combination of observations

$$
\hat{y}_{i} = h{i1} ~y_1 + \cdots+h{ii}~y_i+\cdots+h{in}~y_n.
$$

- The term $h{ii}$ is known as the ***i*th leverage**
    - The larger the value of $h{ii}$, the greater is the effect of the *i*th observation $y_i$ on the *i*th fitted value $\hat{y}_i$.
    - The leverage  $h{ii}$ is based solely on the explanatory variables. 
           - If you change the y values, the leverage does not change.
    - A leverage is deemed to be "unusual" if its value exceeds three times the average (= number of regression coefficients divided by the number of observations.)





`@script`




---
## Let's Practice

```yaml
type: FinalSlide
key: 597c977730
```






`@script`



